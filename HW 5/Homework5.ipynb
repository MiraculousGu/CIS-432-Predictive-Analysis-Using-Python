{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-beb82d1cf0e76f0e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<h1>Homework 5: Understanding linear and trees-based models<\/h1>\n",
                "<h2>Predictive Analytics using Python (CIS432)<\/h2>\n",
                "<h3>Simon Business School<\/h3>\n",
                "\n",
                "__Instructor__: Yaron Shaposhnik\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-bf47835b7a801cc7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Instructions\n",
                "\n",
                "In this homework assignment, you will train linear and tree-based models. You will experiment with their key hyper-parameters and observe how they affect the resulting models. This should improve your understanding of these models and help you create better ones.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c9473db3b6b0d741",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### Answer key\n",
                "\n",
                "This assignment (as well as others) is graded by comparing your answers (that is, the variables and Python objects you create) with precomputed answers. This allows you to get immediate feedback in order to find your errors and correct them. The downside of this approach is that the grading code is strict and even slight deviations from the desired outputs could result in reduction of points. \n",
                "\n",
                "To make this learning experience more efficient, the objects that you are asked to generate are provided to you in the variable `ANSWER_KEY`. Questions may ask you to assign some value (like a number or object such as data frame) to some variable. \n",
                "For example, you might be asked to assign the variable `n_rows` with some value. To view the correct answer simply run the command `ANSWER_KEY['n_rows']`. \n",
                "\n",
                "Note that the answer key is provided to you __for debugging purposes only__. Using it in your final submission or hard-coding solutions __will be considered plagiarism__ and be reported to the student disciplinary committee."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "imports",
                    "locked": true,
                    "points": 10,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# you may ignore this cell\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.pipeline import FeatureUnion\n",
                "from sklearn.impute import MissingIndicator\n",
                "from sklearn.pipeline import Pipeline\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pickle\n",
                "from os import path\n",
                "\n",
                "if os.name == 'nt':\n",
                "    ANSWER_KEY_FILE_NAME = \"answer_key(win).p\"\n",
                "elif os.name == 'posix':\n",
                "    ANSWER_KEY_FILE_NAME = \"answer_key(unix).p\"\n",
                "else:\n",
                "    raise Exception('The code was not tested on',os.name)\n",
                "\n",
                "GENERATE_ANSWER_KEY=False\n",
                "\n",
                "if GENERATE_ANSWER_KEY: \n",
                "    ANSWER_KEY = {} \n",
                "else:        \n",
                "    with open(ANSWER_KEY_FILE_NAME, \"rb\") as f:\n",
                "        ANSWER_KEY = pickle.load( f )           "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8219ebfbd84c42d7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# example for using answer key\n",
                "if GENERATE_ANSWER_KEY==False: \n",
                "    print(ANSWER_KEY['log_reg_coefficients'])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cell-370df72e75f92728",
                    "locked": true,
                    "points": 0,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8654293b8a6657dx",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Beginning of homework 5\n",
                "\n",
                "In previous homework assignments you created and evaluated models based on the HELOC dataset. Let's reload the data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-df2bc3f509b4b171",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "PREPROCESSED_DATA_FILE_NAME = \"preprocessed_data.p\"\n",
                "with open(PREPROCESSED_DATA_FILE_NAME, \"rb\") as f:\n",
                "    PREPROCESSED_DATA = pickle.load( f )               \n",
                "\n",
                "X_train_t_tr,  Y_train_t_tr  = PREPROCESSED_DATA['X_train_t_tr'],  PREPROCESSED_DATA['Y_train_t_tr']\n",
                "X_train_t_val, Y_train_t_val = PREPROCESSED_DATA['X_train_t_val'], PREPROCESSED_DATA['Y_train_t_val']\n",
                "X_test_t,      Y_test        = PREPROCESSED_DATA['X_test_t'],      PREPROCESSED_DATA['Y_test']\n",
                "n = len(Y_train_t_tr) + len(Y_train_t_val) + len(Y_test)\n",
                "column_names = PREPROCESSED_DATA['column_names']\n",
                "\n",
                "print('Train data:      X_train_t_tr:', X_train_t_tr.shape, ' Y_train_t_tr:', Y_train_t_tr.shape)\n",
                "print('Validation data: X_train_t_val:', X_train_t_val.shape, 'Y_train_t_val:', Y_train_t_val.shape)\n",
                "print('Test data:       X_test_t:', X_test_t.shape, '     Y_test:', Y_test.shape)\n",
                "print('\\nThe proportion of train,validation,test data is %.1f:%.1f:%.1f\\n'%(len(Y_train_t_tr)\/n, len(Y_train_t_val)\/n, len(Y_test)\/n))\n",
                "print('column_names:',column_names)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-175d8d7503623e21",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The file `preprocessed_data.p` contains the preprocessed data split into 3 sets: train, validation, and test. The previous code cell loaded the data to memory and assigned it to variables indicating the set and whether the variable refers to features (X) or labels (Y). That is, `X_train_t_tr`, `X_train_t_val`, and `X_test_t` hold the preprocessed train, validation, and test sets, while `Y_train_t_tr`, `Y_train_t_val`, and `Y_test`, hold the corresponding labels. The variable `column_names` holds the list of column names. \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e4c59b6f6ccf05d1",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 1: Linear models"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f62d1d91c2b8543b",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's use the train set to train a few linear models and compare them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f86e37121c83a610",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.naive_bayes import BernoulliNB\n",
                "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
                "from sklearn.linear_model import SGDClassifier"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-73e63e55459160a5",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "log_reg = LogisticRegression(max_iter=10000, random_state=0).fit(X_train_t_tr, Y_train_t_tr) # Logistic regression\n",
                "svc     = SGDClassifier(max_iter=1000, random_state=0).fit(X_train_t_tr, Y_train_t_tr)       # Linear SVM\n",
                "nb      = BernoulliNB().fit(X_train_t_tr, Y_train_t_tr)                                      # Naive Bayes\n",
                "lda     = LinearDiscriminantAnalysis().fit(X_train_t_tr, Y_train_t_tr)                       # LDA"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9e055e19ec2da63e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Train accuracy')\n",
                "print('Log. Reg. accuracy: %.3f'%log_reg.score(X_train_t_tr, Y_train_t_tr))\n",
                "print('Linear SVC accuracy: %.3f'%svc.score(X_train_t_tr, Y_train_t_tr))\n",
                "print('Naive Bayes accuracy: %.3f'%nb.score(X_train_t_tr, Y_train_t_tr))\n",
                "print('LDA accuracy: %.3f'%lda.score(X_train_t_tr, Y_train_t_tr)) \n",
                "\n",
                "print('\\nValidation accuracy')\n",
                "print('Log. Reg. accuracy: %.3f'%log_reg.score(X_train_t_val, Y_train_t_val))\n",
                "print('Linear SVC accuracy: %.3f'%svc.score(X_train_t_val, Y_train_t_val))\n",
                "print('Naive Bayes accuracy: %.3f'%nb.score(X_train_t_val, Y_train_t_val))\n",
                "print('LDA accuracy: %.3f'%lda.score(X_train_t_val, Y_train_t_val)) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e6825fce29584e44",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q1\n",
                "Initialize the variables `log_reg_coefficients`, `svc_coefficients`, `nb_coefficients`, and `lda_coefficients` so that each holds an array with the linear coefficients followed by the intercept corresponding to each model (that is, the intercept should be stored as the last element of `log_reg_coefficients` and the other arrays)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "asdasdasd",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "log_reg_coefficients = \"replace this string with your answer\"\n",
                "svc_coefficients = \"replace this string with your answer\"\n",
                "nb_coefficients = \"replace this string with your answer\"\n",
                "lda_coefficients = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-3a15db9a7490cec2",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# example\n",
                "ANSWER_KEY['log_reg_coefficients']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q1a",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['log_reg_coefficients'], log_reg_coefficients, rtol=0, atol=0.01).all()), 'testing log_reg_coefficients'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q1b",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['svc_coefficients'], svc_coefficients, rtol=0, atol=0.01).all()), 'testing svc_coefficients'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q1c",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['nb_coefficients'], nb_coefficients, rtol=0, atol=0.01).all()), 'testing nb_coefficients'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q1d",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['lda_coefficients'], lda_coefficients, rtol=0, atol=0.01).all()), 'testing lda_coefficients'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-93a3b225d646abfc",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q2 \n",
                "Create the dataframe `linear_coefficients` which holds the coefficients of the 4 models. Each column should correspond to a model (`Log. Reg.`,`SVC`,`NB` and `LDA`; use these exact column names). The rows should hold the column names of the HELOC dataset (which can be found in the variable `column_names` which was initialized above), with one additional row for the intercept of each linear function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-7605774cba4fe172",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "linear_coefficients = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-1a6c7927e345c8f3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['linear_coefficients'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q2",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['linear_coefficients'].round(2)\n",
                "diff = sol.compare(linear_coefficients.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing linear_coefficients'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-499f09e8ef8984a4",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q3\n",
                "Linear classifiers are equivalent up to a multiplication by a constant. Let's divide each classifier by its intercept to see if the models are different. \n",
                "\n",
                "Create the dataframe `linear_coefficients_scaled` which holds the linear coefficients scaled by their intercept values."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-33b9dcc231261cf4",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "linear_coefficients_scaled = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9d504783da807bd0",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['linear_coefficients_scaled'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q3",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['linear_coefficients_scaled'].round(2)\n",
                "diff = sol.compare(linear_coefficients_scaled.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing linear_coefficients_scaled'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ad787b61e62b4f9b",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "By examining `linear_coefficients_scaled`, we see that the resulting linear models are indeed different. We can also see it in the figure below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-bd1b0907045e06c3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['linear_coefficients_scaled'].plot.bar(figsize=(20,5))\n",
                "plt.title('Comparison of linear coefficents among different linear models');"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8965611e1062daab",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We also observe that the models are not identical by looking at their predictions. (Note that the models could be quite similar to each other, which is often the case)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-507132daa4080ea8",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1,4,figsize=(15,4))\n",
                "axes[0].hist(log_reg.predict(X_train_t_val))\n",
                "axes[1].hist(svc.predict(X_train_t_val))\n",
                "axes[2].hist(nb.predict(X_train_t_val))\n",
                "axes[3].hist(lda.predict(X_train_t_val));\n",
                "axes[0].set_title('Log. Reg.\\n (%d \"Bad\" predictions)'%sum(log_reg.predict(X_train_t_val)))\n",
                "axes[1].set_title('SVC\\n (%d \"Bad\" predictions)'%sum(svc.predict(X_train_t_val)))\n",
                "axes[2].set_title('NB\\n (%d \"Bad\" predictions)'%sum(nb.predict(X_train_t_val)))\n",
                "axes[3].set_title('LDA\\n (%d \"Bad\" predictions)'%sum(lda.predict(X_train_t_val)));"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-6ea825c3b7246031",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Next, let us manually compute the predictions that each model makes. To this end, for a given an observation $x$, we will need to multiply each feature of $x$ by its respective coefficient and then add the intercept."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-36ed5957eeeb7869",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# example of manually computing the prediction of the logistic regression model \n",
                "# we will work with the first observation in the data\n",
                "observation = X_train_t_val.iloc[0] \n",
                "\n",
                "# element-wise multiplication by coefficients, summation, and addition of the intercept\n",
                "sum(observation*log_reg_coefficients[:-1]) + log_reg_coefficients[-1] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-365dc90c848deee3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# an equivalent way using np.dot (inner product)\n",
                "np.dot(X_train_t_val.iloc[0],log_reg_coefficients[:-1]) + log_reg_coefficients[-1] "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-54db9d627c2e50f0",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "log_reg_coefficients.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-081037c2e5741998",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The first 34 values of `log_reg_coefficients` hold the linear coefficients and the last value holds the intercept. Since the linear function returned positive value, the prediction is `1`, otherwise, the prediction would have been `0`. In the next cell, we apply the linear function to the first 4 observations in `X_train_t_val`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f3978f00d3345341",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "np.dot(X_train_t_val.iloc[:4,:],log_reg_coefficients[:-1]) + log_reg_coefficients[-1] "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-96ecf93d4943b32d",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We can compare each the result with 0 to see if the predictions are `1` or `0`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-279677e3c4ffdfbb",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "(np.dot(X_train_t_val.iloc[:4,:],log_reg_coefficients[:-1]) + log_reg_coefficients[-1] >0).astype(int)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-2b92539a5faa0d69",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "And this is exactly what we get when we use the logistic regression model prediction function `.predict()`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-5e0d228258b6121b",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "log_reg.predict(X_train_t_val.iloc[:4,:])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-241f1c038947dc3f",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "As a sanity check, we compare the predictions on all datasets:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-50028825aaa30cfa",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "for X in [X_train_t_tr, X_train_t_val, X_test_t]: # compare train, validation and test sets\n",
                "    print(((np.dot(X,log_reg_coefficients[:-1]) + log_reg_coefficients[-1] >0).astype(int) == log_reg.predict(X)).all())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-69b8000d87b1e9a3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q4\n",
                "Using the function `np.dot` and `np.mean` compute the validation set accuracy of the logistic regression model. Assign the answer to the variable `log_reg_val_accuracy` (you should not use the function `.predict()` or any other sk-learn functions)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-0bd43d4842cc3628",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "log_reg_val_accuracy = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q4",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['log_reg_val_accuracy'], log_reg_val_accuracy, rtol=0, atol=0.01).all()), 'testing log_reg_val_accuracy'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-35f8fb4f4bfb213f",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected answer\n",
                "ANSWER_KEY['log_reg_val_accuracy']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-15b2d3a99f4f49a1",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let us now take a closer look at the coefficients of the logistic regression model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c6df1ccaf7f2a64c",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "linear_coefficients['Log. Reg.'].plot.bar(figsize=(15,5));"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ec60eaaf6ea6e5d8",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Some of the coefficients are considerably smaller than others. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-7656368c4c66dc3e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "linear_coefficients['Log. Reg.']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c253dedfd437fbf2",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Does this mean we can ignore them? Let's try."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-444965eeafa51148",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q5\n",
                "The coefficient associated with `ExternalRiskEstimate` is an order of magnitude smaller than some of the other coefficients. Create the pandas series `modified_log_reg` which is identical to `linear_coefficients['Log. Reg.']` with the difference that the coefficient associated with `ExternalRiskEstimate` is set to 0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-dbe950c9b07edd14",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "modified_log_reg = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5a",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['modified_log_reg'].round(2)\n",
                "diff = sol.compare(modified_log_reg.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing modified_log_reg'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-bdf21e60b28e6d0a",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Compute the prediction accuracy on the validation set of the new model represented by `modified_log_reg` and assign the answer to the variable `accuracy_modified_log_reg`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-1393d021feb2c6a3",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "accuracy_modified_log_reg = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5b",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['accuracy_modified_log_reg'], accuracy_modified_log_reg, rtol=0, atol=0.01).all()), 'testing accuracy_modified_log_reg'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 38,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-5e0fcce719fb9120",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['accuracy_modified_log_reg']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-cddab8f8f84ee6da",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The new model is not performing well. The reason is that the magnitude of the features is different:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 39,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-898d71fee4cf5572",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "X_train_t_tr.mean()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-32fda45396d7f9a8",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The average value of `ExternalRiskEstimate` is among the highest. We can compute the average contribution of each feature to the linear function:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-34d3a56394e488f3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "(X_train_t_val* log_reg.coef_[0]).mean().abs().sort_values(ascending=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-b2ac4181a9aff61f",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We see that on average, `ExternalRiskEstimate` has large impact on the predictions, despite it's relative small coefficient value (shown below)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 41,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-fabdcb9550f9e268",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "linear_coefficients['Log. Reg.'].abs().sort_values(ascending=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-d3e974a07b91d8f9",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's try something different. Let's train another logistic model but this time train it without `ExternalRiskEstimate` which happens to be the first feature. initialize the variables `X_train_t_tr_wo_ExternalRiskEstimate` and `Y_train_t_tr_wo_ExternalRiskEstimate` to hold the train data without the feature `ExternalRiskEstimate` (based on `X_train_t_tr` and `Y_train_t_tr`). Similarly, create the variables \n",
                "`X_train_t_val_wo_ExternalRiskEstimate` and `Y_train_t_val_wo_ExternalRiskEstimate` corresponding to the validation set (based on `X_train_t_val` and `Y_train_t_val`). \n",
                "\n",
                "Observe that there no changes are made to the labels here."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-7595c940fa8c32c8",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "X_train_t_tr_wo_ExternalRiskEstimate = \"replace this string with your answer\"\n",
                "Y_train_t_tr_wo_ExternalRiskEstimate = \"replace this string with your answer\"\n",
                "X_train_t_val_wo_ExternalRiskEstimate = \"replace this string with your answer\"\n",
                "Y_train_t_val_wo_ExternalRiskEstimate = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 43,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5c",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train_t_tr_wo_ExternalRiskEstimate'].round(2)\n",
                "diff = sol.compare(X_train_t_tr_wo_ExternalRiskEstimate.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_train_t_tr_wo_ExternalRiskEstimate'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 44,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5d",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_train_t_tr_wo_ExternalRiskEstimate'].round(2)\n",
                "diff = sol.compare(Y_train_t_tr_wo_ExternalRiskEstimate.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_train_t_tr_wo_ExternalRiskEstimate'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 45,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5e",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['X_train_t_val_wo_ExternalRiskEstimate'].round(2)\n",
                "diff = sol.compare(X_train_t_val_wo_ExternalRiskEstimate.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing X_train_t_val_wo_ExternalRiskEstimate'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5f",
                    "locked": true,
                    "points": 1,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['Y_train_t_val_wo_ExternalRiskEstimate'].round(2)\n",
                "diff = sol.compare(Y_train_t_val_wo_ExternalRiskEstimate.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing Y_train_t_val_wo_ExternalRiskEstimate'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e06f476bfd287465",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Sanity check:\n",
                "print('dimensions of X_train_t_tr:',X_train_t_tr.shape) \n",
                "print('dimensions of X_train_t_tr_wo_ExternalRiskEstimate:',ANSWER_KEY['X_train_t_tr_wo_ExternalRiskEstimate'].shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-44f89af68b76ea39",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Now let's train and evaluate the model that does not use the feature `ExternalRiskEstimate`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-1e7c9a4537f1d32e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "log_reg_wo_ExternalRiskEstimate = LogisticRegression(max_iter=10000).fit(ANSWER_KEY['X_train_t_tr_wo_ExternalRiskEstimate'], \n",
                "                                                                         ANSWER_KEY['Y_train_t_tr_wo_ExternalRiskEstimate']) "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8f5e2b5354c55169",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Compute the train and validation accuracies of the new linear model `log_reg_wo_ExternalRiskEstimate` and assign the results to the variables `accuracy_retrained_model_train` and `accuracy_retrained_model_validation`. Create the variable `retrained_log_reg` which is a pandas series whose indexes are similar to that of `modified_log_reg` and whose values are used by the linear classifier `log_reg_wo_ExternalRiskEstimate`. \n",
                "\n",
                "Note that while the feature `ExternalRiskEstimate` is not needed for the model `log_reg_wo_ExternalRiskEstimate`, we keep it to make it easier to compare it with other models. The coefficient associated with `ExternalRiskEstimate` should simply be set equal to 0."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e5f6c2916f9f2e71",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "accuracy_retrained_model_train = \"replace this string with your answer\"\n",
                "accuracy_retrained_model_validation = \"replace this string with your answer\"\n",
                "retrained_log_reg = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 50,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5g",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['accuracy_retrained_model_train'], accuracy_retrained_model_train, rtol=0, atol=0.01).all()), 'testing accuracy_retrained_model_train'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 51,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5h",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['accuracy_retrained_model_validation'], accuracy_retrained_model_validation, rtol=0, atol=0.01).all()), 'testing accuracy_retrained_model_validation'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q5i",
                    "locked": true,
                    "points": 3,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['retrained_log_reg'].round(2)\n",
                "diff = sol.compare(retrained_log_reg.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing retrained_log_reg'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-2ee5209d702f9eb4",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's compare accuracies and linear coefficients"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8d9bb59489352aee",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Log. Reg. retrained model train accuracy: %.3f'%accuracy_retrained_model_train)\n",
                "print('Log. Reg. retrained model validation accuracy: %.3f\\n'%accuracy_retrained_model_validation)\n",
                "\n",
                "print('Log. Reg. original model train accuracy: %.3f'%log_reg.score(X_train_t_tr, Y_train_t_tr))\n",
                "print('Log. Reg. original model validation accuracy: %.3f'%log_reg.score(X_train_t_val, Y_train_t_val))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f710397e7fa46b4e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The performance (in terms of accuracy) is quite similar. Let's compare the coefficients:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-407bd2a9d373a0ef",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "pd.merge(linear_coefficients['Log. Reg.'],ANSWER_KEY['retrained_log_reg'], left_index=True, right_index=True).plot.bar(figsize=(20,8));"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-020a4d8635ab5916",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# simliar plot only without the intercept\n",
                "pd.merge(linear_coefficients['Log. Reg.'],ANSWER_KEY['retrained_log_reg'], left_index=True, right_index=True).iloc[:-1,:].plot.bar(figsize=(20,8));"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f9c14ecb58624ced",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The coefficients are somewhat different. It appears that training a logistic regression model without the feature `ExternalRiskEstimate` results in a redistribution of the coefficients.\n",
                "\n",
                "It turns out that in practice, there are often multiple models whose performance is very similar. This, for example, could result from a correlation between features which allows using different subsets of features. It raises the question of which model to use? \n",
                "\n",
                "Typical practical answers are:\n",
                "* use the simplest one. This is known as Occam's razor, and can be obtained by trial and error, regularization, stepwise selection (see Chapter 6 in Introduction in Statistical Learning), or integer programming based models (e.g., SLIM and RiskSLIM).\n",
                "* look carefully at the features used by each model and see which make more sense in the context of the specific prediction problem.\n",
                "\n",
                "When debating between different models (trees vs. linear), one should consider the perspective of the user of the model and think about which one would be better suited for him or her for informing decisions. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-20009f3c47bad982",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "__Estimating probabilities__\n",
                "\n",
                "Finally, let's briefly explore some functionalities of probabilistic models. The logistic regression model not only makes predictions (1 vs. 0) but also estimates the probability that an observation is predicted as 1 or 0. \n",
                "\n",
                "In sk-learn, the function `predict` returns a discrete prediction while the function `predict_proba` returns probability."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 56,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-b292a952ff036697",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# make predictions about observations 0 and 1 in the validation set\n",
                "log_reg.predict(X_train_t_val.iloc[[0,1],:]) "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-94804552ba00d023",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "#  compute probabilities corresponding to observation 0 and 1 in the validation set\n",
                "print(log_reg.predict_proba(X_train_t_val.iloc[[0,1],:]))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-7ec14a3466c2edff",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The probability that the label associated with observation #0 is 1, is equal to 0.82, which is greater than 0.5 and therefore the prediction is 1. \n",
                "\n",
                "Let's look at the distribution of predictions. We will bucket observations according to the probabilities estimated by the model, and compute the accuracy in each bucket."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-4b75a98511bacfd9",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q6\n",
                "\n",
                "Create the dataframe `df_probs` which holds the following information about the validation set `X_train_t_val`:\n",
                "1. `Prob(0)` - the probability that the model `log_reg` estimates for the label 0\n",
                "2. `Prob(1)` - the probability that the model `log_reg` estimates for the label 1\n",
                "3. `Prediction` - the prediction\n",
                "4. `Label` - the true label\n",
                "5. `Correct prediction` - is the prediction correct\n",
                "\n",
                "An example of the output is provided below.\n",
                "\n",
                "__Use may the function `log_reg.predict_proba` to compute probabilities.__"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 58,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-962b1067257a3f36",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "df_probs = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 59,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-24e4b9aa5dfbd651",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['df_probs'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 115,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q6",
                    "locked": true,
                    "points": 6,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL) (required handling rounding)\n",
                "sol = ANSWER_KEY['df_probs']\n",
                "diff = sol.loc[:,\"Correct prediction\"].compare(df_probs.loc[:,\"Correct prediction\"], keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing \"Correct prediction\" column of df_probs'\n",
                "\n",
                "diff = pd.Series({\"Prob(0)\" : True,\n",
                "                  \"Prob(1)\" : True,\n",
                "                  \"Prediction\" : True,\n",
                "                  \"Label\" : True}).compare(((ANSWER_KEY['df_probs'].iloc[:,:-1] - df_probs.iloc[:,:-1]).abs() <= 0.01).all(), keep_equal=False)\n",
                "assert(len(diff)==0), 'testing remaining columns of df_probs'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-7fafbb9e9c171d74",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "fig,axes = plt.subplots(1,2,figsize=(20,8))\n",
                "axes[0].hist(ANSWER_KEY['df_probs']['Prob(1)'], bins=50)\n",
                "axes[0].set_title('Distribution of predictions')\n",
                "ANSWER_KEY['df_probs'].groupby('Prob(1)').mean()['Correct prediction'].plot(ax=axes[1], title='% of correct predictions as function of Prob(1)');\n",
                "axes[1].axhline(ANSWER_KEY['df_probs']['Correct prediction'].mean());"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-0063441b2d714f8c",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The figure shows that in many cases (when the probability is sufficiently small or large; see the histogram on the left), we are more confident about the model predictions (that's when the percentage of correct predictions is high). \n",
                "\n",
                "However, there are also many observations for which the probability is close to 0.5. In these cases we are less confident about our predictions (on the right figure we see that prediction accuracy drops when the probability is around 0.5). \n",
                "\n",
                "Intuitively, this is because observations for which the predicted probability is close to 0.5 are close to the decision boundary, an area that is typically more difficult to classify."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c10058dff600b9df",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## Part 2: Tree-based models\n",
                "\n",
                "We now switch to working with tree-based models. Let's train a decision tree."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-1557c19c51c4fc37",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "from sklearn import tree\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.ensemble import BaggingClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.ensemble import AdaBoostClassifier\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.model_selection import cross_val_score\n",
                "from sklearn.model_selection import GridSearchCV\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from IPython.display import Image \n",
                "from IPython.display import IFrame\n",
                "import pydot_ng as pydot "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-00cc5b427be4b535",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q7 Decision trees"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-73e63e55459160ax",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "clf_tree = DecisionTreeClassifier(max_depth=1, random_state=0).fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-816f48b4894e7ac3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Compute the train and validation accuracies and assign them to the variables `train_accuracy_DT` and `val_accuracy_DT`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 64,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9e055e19ec2da63x",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "train_accuracy_DT = \"replace this string with your answer\"\n",
                "val_accuracy_DT = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q7a",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['train_accuracy_DT'], train_accuracy_DT, rtol=0, atol=0.01).all()), 'testing train_accuracy_DT'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 66,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q7b",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['val_accuracy_DT'], val_accuracy_DT, rtol=0, atol=0.01).all()), 'testing val_accuracy_DT'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 67,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-2941e2827881842a",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Train accuracy (DT): %.3f'%ANSWER_KEY['train_accuracy_DT'])\n",
                "print('Validation accuracy (DT): %.3f'%ANSWER_KEY['val_accuracy_DT'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-8ed35dde757059e8",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's visualize the tree"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 68,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ed1a2e72502f5bd0",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "with open(\"tree_stump.dot\", 'w') as f:                   \n",
                "    # export visualization of model to a .dot file\n",
                "    tree.export_graphviz(clf_tree, out_file=f, feature_names=column_names, filled=True, label='all')     \n",
                "    \n",
                "pydot.graph_from_dot_file('tree_stump.dot').write_pdf('tree_stump.pdf') # convert .dot to .pdf\n",
                "IFrame('tree_stump.pdf', width=400, height=300)                         # display pdf in jupyter"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ebe1dad1392c57c3",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The model is surprisingly accurate considering the fact that it is a decision stump (decision tree of depth 1), and that the accuracy is close to other models we previously trained on this dataset.\n",
                "\n",
                "Let's see what happens when we change the depth of the tree. Initialize the variable `tree_accuracy` to a dataframe whose indexes run from 1 to 12, with two columns, one for `Train accuracy` and one for `Validation accuracy`. Use the default parameters of `DecisionTreeClassifier` except for the depth and setting `random_state=0`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e90809523b22bbf0asdf",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "tree_accuracy = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 70,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f88d28f4c7f69465",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['tree_accuracy'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 71,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q7c",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['tree_accuracy'].round(2)\n",
                "diff = sol.compare(tree_accuracy.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing tree_accuracy'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 72,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-4e7ac4056de98133asd",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['tree_accuracy'].plot();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-6dcf8b7be72e3913",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Plotting the train and validation accuracies as a function of the tree depth, we observe that there is no improvement the the validation accuracy (in fact there is a deterioration at some point), while the train accuracy keeps improving. This is an indication of overfitting. This is not surprising with decision trees which can perfectly classify any dataset with sufficiently deep trees (as long as there are no two observations in the dataset with identical features and opposite predictions).\n",
                "\n",
                "Let's try to tune the hyperparameters of the model to improve its performance.  "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 73,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f22cca94769e1356",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "IFrame('https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.tree.DecisionTreeClassifier.html', width=950, height=300)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 74,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-762802ade2a2e6d8",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "param_grid = [{'max_depth':range(1,13),\n",
                "               'min_samples_leaf':[10,20,100],\n",
                "               'max_leaf_nodes':[2,4,6,20,100,10000]}]\n",
                "\n",
                "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=0), \n",
                "                           param_grid, \n",
                "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0), \n",
                "                           scoring='accuracy')\n",
                "\n",
                "grid_search.fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c6408b095c0cbdb7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Read the documentation to see what each of the hyperparameters specified above does.\n",
                "\n",
                "Create the dataframe `tree_accuracy_grid` based on the results of the grid search, which are stored in the variable `grid_search`. The dataframe should have a row per each configuration, and columns for the hyper parameters `max_depth`, `max_leaf_nodes`, `min_samples_leaf`, and `Accuracy`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f58a74a1b0867d07",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "tree_accuracy_grid = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-49dc4b1ab071105c",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['tree_accuracy_grid'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q7d",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['tree_accuracy_grid'].round(2)\n",
                "diff = sol.compare(tree_accuracy_grid.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing tree_accuracy_grid'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9699edc2b7b10ad4",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1,2,figsize=(20,5))\n",
                "plt.suptitle('Decision trees: CV Accuracy vs. depth \\n(Distribution over hyperparameters that share the same tree depth)')\n",
                "sns.boxplot(x=\"max_depth\", y='Accuracy', data=ANSWER_KEY['tree_accuracy_grid'], ax=axes[0]);\n",
                "tree_accuracy.plot(ax=axes[1]);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-600e5c1b5402e803",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The figure above shows the cross validation accuracy as a function of the maximal depth (since we're exploring many configuration, for each depth we have several configurations whose accuracies can be shown as a distribution). The right figure is identical to the figure presented earlier. Observe that the y-axis scale is different.\n",
                "\n",
                "We see that with the right tuning, we can mitigate the overfitting, which are due to the increasing depth. However, it appears that we do not improve significantly the performance and we may simply select the decision stump."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ba22b2fc73e1796x",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q8 Ensemble methods - Random forests\n",
                "\n",
                "Instead of creating a single increasingly more complex trees, let's to create an ensemble of trees. Compute the train and validation accuracies of the Random Forest model below and assign them to the variables `train_accuracy_RF` and `val_accuracy_RF`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-5de789d70f7cc436",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "rf = RandomForestClassifier(max_depth=1, random_state=0).fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9e05dfghdfgh",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "train_accuracy_RF = \"replace this string with your answer\"\n",
                "val_accuracy_RF = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 81,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q8a",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['train_accuracy_RF'], train_accuracy_RF, rtol=0, atol=0.01).all()), 'testing train_accuracy_RF'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 82,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q8b",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['val_accuracy_RF'], val_accuracy_RF, rtol=0, atol=0.01).all()), 'testing val_accuracy_RF'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-733ccd822e240a08s",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Train accuracy (RF): %.3f'%ANSWER_KEY['train_accuracy_RF'])\n",
                "print('Validation accuracy (RF): %.3f'%ANSWER_KEY['val_accuracy_RF'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-419beba7266ea94e",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We gain a roughly 1% improvement comparing to the decision stump. Let's try to improve the model by performing hyper-parameter tuning. Read the documentation to see what each of the hyperparameters specified above does (https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.RandomForestClassifier.html).\n",
                "\n",
                "Note: expect the running time to be longer here. We train `3x2x3x4` RF models, each consisting of 10-50 decision trees.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9a19c2e23379ced4",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "param_grid = [{'n_estimators':[10,20,50],\n",
                "               'max_depth':range(1,8),\n",
                "               'min_samples_leaf':[10,20,100],\n",
                "               'max_leaf_nodes':[2,4,8,16]}]\n",
                "\n",
                "grid_search = GridSearchCV(RandomForestClassifier(random_state=0), \n",
                "                           param_grid, \n",
                "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0), \n",
                "                           scoring='accuracy')\n",
                "\n",
                "grid_search.fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-c6408b095c0cbdbx",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Create the dataframe `rf_accuracy_grid` based on the results of the grid search, which are stored in the variable `grid_search`. The dataframe should have a row per each configuration, and columns for the hyper parameters `n_estimators`, `max_depth`, `max_leaf_nodes`, `min_samples_leaf`, and `Accuracy`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f58a74a1b0867d09",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "rf_accuracy_grid = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 86,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-49dc4b1ab0711059",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# expected output\n",
                "ANSWER_KEY['rf_accuracy_grid'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 87,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q8c",
                    "locked": true,
                    "points": 6,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['rf_accuracy_grid']\n",
                "diff = sol.compare(rf_accuracy_grid, keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing rf_accuracy_grid'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 88,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-65fd0375fa3b32a7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(1,2,figsize=(20,5))\n",
                "plt.suptitle('CV Accuracy vs. depth: DT (left) and RF (right)\\n(Distribution over hyperparameters that share tree depth)')\n",
                "sns.boxplot(x=\"max_depth\", y='Accuracy', data=ANSWER_KEY['tree_accuracy_grid'], ax=axes[0]);\n",
                "sns.boxplot(x=\"max_depth\", y='Accuracy', data=ANSWER_KEY['rf_accuracy_grid'], ax=axes[1]);\n",
                "axes[0].set_ylim(0.65,0.74);axes[1].set_ylim(0.65,0.74);"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-53d79bf0679c4ec9",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We see in the figure above that with some hyperparameter tuning we can further improve the accuracy of the RF model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 89,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-26e866f810776e22",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# the best configuration\n",
                "grid_search.best_params_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 90,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-b2db961d88126d9a",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# a model trained using the best configuration on all folds\n",
                "best_RF_model = grid_search.best_estimator_\n",
                "best_RF_model"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ba22b2fc73e1796",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Compute the train and validation accuracies of the optimized Random Forest `best_RF_model` and assign them to the variables `train_accuracy_RF_opt` and `val_accuracy_RF_opt`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 91,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9e055e1sdfgfg",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "train_accuracy_RF_opt = \"replace this string with your answer\"\n",
                "val_accuracy_RF_opt = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 92,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q8d",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['train_accuracy_RF_opt'], train_accuracy_RF_opt, rtol=0, atol=0.01).all()), 'testing train_accuracy_RF_opt'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 93,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q8e",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['val_accuracy_RF_opt'], val_accuracy_RF_opt, rtol=0, atol=0.01).all()), 'testing val_accuracy_RF_opt'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 94,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-cf0af6ed6ab25fe1",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Train accuracy (RF optimized): %.3f'%ANSWER_KEY['train_accuracy_RF_opt'])\n",
                "print('Validation accuracy (RF optimized): %.3f'%ANSWER_KEY['val_accuracy_RF_opt'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-729711bfd6e7303a",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "An issue that arises when working with ensemble models is that now our model averages 10 trees (n_estimators=10 in the best configuration), each of a potential depth of 7 (that is, with up to $2^7=128$ leaf nodes). This makes it difficult to understand how the model works. One approach that is used in practice is to compute the _feature importance_ by computing the overall improvement in the model that can be attributed to splitting using each feature. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 95,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-5206d1d513467ca4",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# plot feature importance\n",
                "pd.Series(data=grid_search.best_estimator_.feature_importances_, \n",
                "          index=column_names).sort_values().plot.bar(figsize=(15,5), \n",
                "                                                     title='Feature importance of best RF model');"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f82cd9f78360b137asd",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "It seems that our RF model still heavily relies on the feature `ExternalRiskEstimate`, but now it also utilizes other features.\n",
                "\n",
                "Let's see how the CV accuracy is affected by the number of trees in the ensemble. Initialize the variable `rf_accuracy` to a dataframe whose indexes run from 10 to 190 with increments of 10, with two columns, one for `Train accuracy` and one for `Validation accuracy`. You should create the RF classifiers as follows: `RandomForestClassifier(n_estimators=?, random_state=0, max_depth=1)` where ? is replaced by the ensemble size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 96,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e90809523b22bbf01234",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "rf_accuracy = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 97,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ddac90e20ac9dce7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['rf_accuracy'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 98,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q8f",
                    "locked": true,
                    "points": 6,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['rf_accuracy'].round(2)\n",
                "diff = sol.compare(rf_accuracy.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing rf_accuracy'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-4e7ac4056de98133adsf",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['rf_accuracy'].plot();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-1df776e45b7aae31",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "We observe that the performance of the ensemble tends to initially improve and then stabilize as the ensemble grows. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-ba22b2fc73e179",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "### q9  Ensemble methods - Boosting\n",
                "\n",
                "Let's to create another ensemble of trees, this time using Boosting. Compute the train and validation accuracies of the Boosting model below and assign them to the variables `train_accuracy_boosting` and `val_accuracy_boosting`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 100,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-94c7edf7d3f03680",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "clf_boosting = AdaBoostClassifier(random_state=0).fit(X_train_t_tr, Y_train_t_tr)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 101,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9e055sdfgdsfg",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "train_accuracy_boosting = \"replace this string with your answer\"\n",
                "val_accuracy_boosting = \"replace this string with your answer\"\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q9a",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "    ### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['train_accuracy_boosting'], train_accuracy_boosting, rtol=0, atol=0.01).all()), 'testing train_accuracy_boosting'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 103,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q9b",
                    "locked": true,
                    "points": 2,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST\n",
                "assert(np.isclose(ANSWER_KEY['val_accuracy_boosting'], val_accuracy_boosting, rtol=0, atol=0.01).all()), 'testing val_accuracy_boosting'\n",
                "### END TEST"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 104,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-733ccd822e240a08",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Train accuracy (boosting): %.3f'%ANSWER_KEY['train_accuracy_boosting'])\n",
                "print('Validation accuracy (boosting): %.3f'%ANSWER_KEY['val_accuracy_boosting'])\n",
                "print('\\nTrain accuracy (RF optimized): %.3f'%ANSWER_KEY['train_accuracy_RF_opt'])\n",
                "print('Validation accuracy (RF optimized): %.3f'%ANSWER_KEY['val_accuracy_RF_opt'])\n",
                "print('\\nTrain accuracy (DT): %.3f'%ANSWER_KEY['train_accuracy_DT'])\n",
                "print('Validation accuracy (DT): %.3f'%ANSWER_KEY['val_accuracy_DT'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e33a229b5d3ae428",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Using the default hyperparameters, we created an ensemble model that outperforms the previous models. This will not always be the case, and one should not conclude that Boosting is always superior to Random Forests. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-d615a5f35aba746d",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "There are several important hyperparameters for tuning the Boosting algorithm. One is the `base_estimator` which refers to the base model that we repeatedly train on (slight variations of) the data. The other two are `n_estimators` and `learning_rate` which go together. The first controlling the size of the ensemble (e.g., number of trees), and the second is the \"step size\", intuitively indicating the importance we give to each model. The smaller the learning rate, the more iterations we may need to reach the optimal ensemble. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-f82cd9f78360b137",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Let's illustrate the effect of using a small learning rate.\n",
                "\n",
                "Initialize the variable `boosting_accuracy_learning_rate_0_01` to a dataframe whose indexes run from 10 to 190 with increments of 10, with two columns, one for `Train accuracy` and one for `Validation accuracy`. Create an  AdaBoost classifier as follows: `AdaBoostClassifier(n_estimators=?, random_state=0, learning_rate=0.01)` where ? should be replaced by the ensemble size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 105,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e90809523b22bbf0234",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "boosting_accuracy_learning_rate_0_01 = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 106,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-9106507a4ab238f6",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['boosting_accuracy_learning_rate_0_01'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 107,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q9c",
                    "locked": true,
                    "points": 5,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['boosting_accuracy_learning_rate_0_01'].round(2)\n",
                "diff = sol.compare(boosting_accuracy_learning_rate_0_01.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing boosting_accuracy_learning_rate_0_01'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-4e7ac4056de98133asdf",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['boosting_accuracy_learning_rate_0_01'].plot();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-2c0820e3f20a0349",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Even though we trained an ensemble with 190 trees, the learning rate is small (0.01) and therefore we will need much larger ensembles to obtain better models (assuming we keep the same learning rate).\n",
                "\n",
                "Let's try a higher learning rate and train a larger ensemble. Initialize the variable `boosting_accuracy_learning_rate_1` to a dataframe whose indexes run from 10 to 390 with increments of 10, with two columns, one for `Train accuracy` and one for `Validation accuracy`. Create an  AdaBoost classifier as follows: `AdaBoostClassifier(n_estimators=?, random_state=0, learning_rate=1)` where ? should be replaced by the ensemble size."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 109,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-e90809523b22bbf0",
                    "locked": false,
                    "schema_version": 3,
                    "solution": true,
                    "task": false
                }
            },
            "outputs": [],
            "source": [
                "boosting_accuracy_learning_rate_1 = \"replace this string with your answer\"\n",
                "\n",
                "###\n",
                "### YOUR CODE HERE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 110,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-2c444f59d44e0bd7",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['boosting_accuracy_learning_rate_1'].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 111,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "q9d",
                    "locked": true,
                    "points": 6,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "### BEGIN TEST (DO NOT REMOVE CELL)\n",
                "sol = ANSWER_KEY['boosting_accuracy_learning_rate_1'].round(2)\n",
                "diff = sol.compare(boosting_accuracy_learning_rate_1.round(2), keep_equal=False, align_axis=0)\n",
                "assert(len(diff)==0), 'testing boosting_accuracy_learning_rate_1'\n",
                "### END TEST "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 112,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-4e7ac4056de98133",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "scrolled": true,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "ANSWER_KEY['boosting_accuracy_learning_rate_1'].plot();"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-eb8202cd695a422f",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Now that the learning rate is sufficiently large, we achieve the optimal ensemble size using approximately 60 trees. Beyond that point, we start to overfit: the training accuracy keeps improving while the validation accuracy worsens as the ensemble grows.  "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-3e175e7ffcd32720",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "Note that simliarly to linear models where there are many linear models that work differently, there are also many variants of the Boosting algorithm. See, for example, [sk-learn](https:\/\/scikit-learn.org\/stable\/modules\/ensemble.html), [XGBoost](https:\/\/xgboost.readthedocs.io\/en\/latest\/), and [LightGBM](https:\/\/github.com\/Microsoft\/LightGBM)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-a31e421e4a6b064f",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# Summary\n",
                "\n",
                "\n",
                "In this homework assignment, we experimented with linear and tree-based models and their key hyper-parameters to observe how they affect the resulting models. The optional reading and assignments cover additional material about the models used in this assignment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 113,
            "metadata": {
                "nbgrader": {
                    "grade": true,
                    "grade_id": "cell-56a7f83815146078",
                    "locked": true,
                    "points": 0,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "grade_id": "cell-de4459e60753beb5",
                    "locked": true,
                    "schema_version": 3,
                    "solution": false,
                    "task": false
                },
                "editable": false,
                "deletable": false
            },
            "source": []
        }
    ],
    "metadata": {
        "celltoolbar": "Create Assignment",
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        },
        "latex_envs": {
            "LaTeX_envs_menu_present": true,
            "autoclose": false,
            "autocomplete": true,
            "bibliofile": "biblio.bib",
            "cite_by": "apalike",
            "current_citInitial": 1,
            "eqLabelWithNumbers": true,
            "eqNumInitial": 1,
            "hotkeys": {
                "equation": "Ctrl-E",
                "itemize": "Ctrl-I"
            },
            "labels_anchors": false,
            "latex_user_defs": false,
            "report_style_numbering": false,
            "user_envs_cfg": false
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": [],
            "number_sections": false,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {
                "height": "829px",
                "left": "48px",
                "top": "110px",
                "width": "343.969px"
            },
            "toc_section_display": true,
            "toc_window_display": true
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}